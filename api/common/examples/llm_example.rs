//! å¤§æ¨¡åž‹è°ƒç”¨æ¨¡å—ä½¿ç”¨ç¤ºä¾‹
//! 
//! å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€çš„å¤§æ¨¡åž‹è°ƒç”¨æŽ¥å£

use common::llm::{
    LlmClient, LlmClientBuilder, LlmConfig, ChatMessage, ChatCompletionRequest
};
use std::env;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    tracing_subscriber::fmt::init();
    
    println!("=== å¤§æ¨¡åž‹è°ƒç”¨æ¨¡å—ç¤ºä¾‹ ===\n");
    
    // æ–¹å¼1: æ‰‹åŠ¨åˆ›å»ºå®¢æˆ·ç«¯å¹¶æ·»åŠ é…ç½®
    let client = LlmClient::new();
    
    // ä»ŽçŽ¯å¢ƒå˜é‡èŽ·å– API å¯†é’¥ï¼ˆå®žé™…ä½¿ç”¨æ—¶ï¼‰
    // let openai_key = env::var("OPENAI_API_KEY").unwrap_or_else(|_| "your-openai-key".to_string());
    // let deepseek_key = env::var("DEEPSEEK_API_KEY").unwrap_or_else(|_| "your-deepseek-key".to_string());
    
    // ç¤ºä¾‹é…ç½®ï¼ˆè¯·æ›¿æ¢ä¸ºçœŸå®žçš„ API å¯†é’¥ï¼‰
    let openai_key = "your-openai-api-key";
    let deepseek_key = "your-deepseek-api-key";
    
    // æ·»åŠ  OpenAI é…ç½®
    if openai_key != "your-openai-api-key" {
        let openai_config = LlmConfig::openai(openai_key)
            .with_default_model("gpt-3.5-turbo")
            .with_timeout(30)
            .with_logging(true);
        
        match client.add_config("openai", openai_config).await {
            Ok(_) => println!("âœ… OpenAI é…ç½®æ·»åŠ æˆåŠŸ"),
            Err(e) => println!("âŒ OpenAI é…ç½®æ·»åŠ å¤±è´¥: {}", e),
        }
    }
    
    // æ·»åŠ  DeepSeek é…ç½®
    if deepseek_key != "your-deepseek-api-key" {
        let deepseek_config = LlmConfig::deepseek(deepseek_key)
            .with_default_model("deepseek-chat")
            .with_timeout(30)
            .with_logging(true);
        
        match client.add_config("deepseek", deepseek_config).await {
            Ok(_) => println!("âœ… DeepSeek é…ç½®æ·»åŠ æˆåŠŸ"),
            Err(e) => println!("âŒ DeepSeek é…ç½®æ·»åŠ å¤±è´¥: {}", e),
        }
    }
    
    // æ–¹å¼2: ä½¿ç”¨æž„å»ºå™¨æ¨¡å¼ï¼ˆå¦‚æžœæœ‰æœ‰æ•ˆçš„ API å¯†é’¥ï¼‰
    /*
    let client = LlmClientBuilder::new()
        .with_openai("openai", openai_key)
        .with_deepseek("deepseek", deepseek_key)
        .with_gemini("gemini", "your-gemini-key")
        .with_claude("claude", "your-claude-key")
        .with_default("openai")
        .build()
        .await?;
    */
    
    // åˆ—å‡ºæ‰€æœ‰é…ç½®
    let configs = client.list_configs().await;
    println!("\nðŸ“‹ å·²é…ç½®çš„æä¾›å•†: {:?}", configs);
    
    if !configs.is_empty() {
        // è®¾ç½®é»˜è®¤é…ç½®
        if let Err(e) = client.set_default_config(&configs[0]).await {
            println!("âŒ è®¾ç½®é»˜è®¤é…ç½®å¤±è´¥: {}", e);
        } else {
            println!("âœ… é»˜è®¤é…ç½®è®¾ç½®ä¸º: {}", configs[0]);
        }
        
        // ç¤ºä¾‹1: ç®€å•èŠå¤©
        println!("\nðŸ¤– ç¤ºä¾‹1: ç®€å•èŠå¤©");
        match client.chat("ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±", None).await {
            Ok(response) => println!("å›žå¤: {}", response),
            Err(e) => println!("èŠå¤©å¤±è´¥: {}", e),
        }
        
        // ç¤ºä¾‹2: ä½¿ç”¨å®Œæ•´çš„èŠå¤©å®ŒæˆæŽ¥å£
        println!("\nðŸ¤– ç¤ºä¾‹2: å®Œæ•´èŠå¤©å®Œæˆ");
        let request = ChatCompletionRequest::simple(
            "".to_string(), // ä½¿ç”¨é»˜è®¤æ¨¡åž‹
            vec![
                ChatMessage::system("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆ"),
                ChatMessage::user("è¯·åˆ†æžä¸€ä¸‹å½“å‰è‚¡å¸‚çš„è¶‹åŠ¿"),
            ],
        )
        .with_temperature(0.7)
        .with_max_tokens(500);
        
        match client.chat_completion(request, None).await {
            Ok(response) => {
                if let Some(choice) = response.choices.first() {
                    println!("åˆ†æžç»“æžœ: {}", choice.message.content);
                    if let Some(usage) = response.usage {
                        println!("Token ä½¿ç”¨: è¾“å…¥={}, è¾“å‡º={}, æ€»è®¡={}", 
                            usage.prompt_tokens, usage.completion_tokens, usage.total_tokens);
                    }
                }
            }
            Err(e) => println!("åˆ†æžå¤±è´¥: {}", e),
        }
        
        // ç¤ºä¾‹3: ä¼šè¯ç®¡ç†
        println!("\nðŸ’¬ ç¤ºä¾‹3: ä¼šè¯ç®¡ç†");
        let session = client.create_session().await;
        println!("åˆ›å»ºä¼šè¯: {}", session.id);
        
        // åœ¨ä¼šè¯ä¸­å‘é€å¤šæ¡æ¶ˆæ¯
        let questions = vec![
            "ä»€ä¹ˆæ˜¯é‡åŒ–äº¤æ˜“ï¼Ÿ",
            "é‡åŒ–äº¤æ˜“æœ‰å“ªäº›å¸¸è§ç­–ç•¥ï¼Ÿ",
            "å¦‚ä½•è¯„ä¼°ç­–ç•¥çš„é£Žé™©ï¼Ÿ",
        ];
        
        for question in questions {
            match client.chat_in_session(session.id, question, None).await {
                Ok(answer) => println!("Q: {}\nA: {}\n", question, answer),
                Err(e) => println!("ä¼šè¯èŠå¤©å¤±è´¥: {}", e),
            }
        }
        
        // èŽ·å–ä¼šè¯ä¿¡æ¯
        if let Some(updated_session) = client.get_session(session.id).await {
            println!("ä¼šè¯æ¶ˆæ¯æ•°é‡: {}", updated_session.messages.len());
        }
        
        // ç¤ºä¾‹4: å¤šæä¾›å•†å¯¹æ¯”ï¼ˆå¦‚æžœé…ç½®äº†å¤šä¸ªæä¾›å•†ï¼‰
        if configs.len() > 1 {
            println!("\nðŸ”„ ç¤ºä¾‹4: å¤šæä¾›å•†å¯¹æ¯”");
            let question = "ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½";
            
            for config_name in &configs {
                match client.chat(question, Some(config_name)).await {
                    Ok(response) => println!("{}: {}", config_name, response),
                    Err(e) => println!("{} å¤±è´¥: {}", config_name, e),
                }
            }
        }
        
        // ç¤ºä¾‹5: èŽ·å–æ¨¡åž‹åˆ—è¡¨
        println!("\nðŸ“ ç¤ºä¾‹5: èŽ·å–æ¨¡åž‹åˆ—è¡¨");
        match client.list_models(None).await {
            Ok(models) => {
                println!("å¯ç”¨æ¨¡åž‹æ•°é‡: {}", models.data.len());
                for model in models.data.iter().take(5) {
                    println!("- {}", model.id);
                }
            }
            Err(e) => println!("èŽ·å–æ¨¡åž‹åˆ—è¡¨å¤±è´¥: {}", e),
        }
        
        // æ¸…ç†ä¼šè¯
        if client.delete_session(session.id).await {
            println!("âœ… ä¼šè¯å·²åˆ é™¤");
        }
    } else {
        println!("âš ï¸  æ²¡æœ‰é…ç½®ä»»ä½•æä¾›å•†ï¼Œè¯·è®¾ç½®æœ‰æ•ˆçš„ API å¯†é’¥");
        
        // å±•ç¤ºé…ç½®ç¤ºä¾‹
        println!("\nðŸ“– é…ç½®ç¤ºä¾‹:");
        println!("1. OpenAI:");
        println!("   let config = LlmConfig::openai(\"your-api-key\");");
        println!("   client.add_config(\"openai\", config).await?;");
        
        println!("\n2. DeepSeek:");
        println!("   let config = LlmConfig::deepseek(\"your-api-key\");");
        println!("   client.add_config(\"deepseek\", config).await?;");
        
        println!("\n3. è‡ªå®šä¹‰æä¾›å•†:");
        println!("   let config = LlmConfig::custom(\"your-api-key\", \"https://api.example.com/v1\", \"model-name\");");
        println!("   client.add_config(\"custom\", config).await?;");
    }
    
    // èŽ·å–ç»Ÿè®¡ä¿¡æ¯
    let stats = client.get_session_stats().await;
    println!("\nðŸ“Š ç»Ÿè®¡ä¿¡æ¯: {:?}", stats);
    
    println!("\nâœ… å¤§æ¨¡åž‹è°ƒç”¨æ¨¡å—ç¤ºä¾‹è¿è¡Œå®Œæˆ!");
    
    Ok(())
}

/// å±•ç¤ºé”™è¯¯å¤„ç†
async fn demonstrate_error_handling() {
    println!("\nðŸš¨ é”™è¯¯å¤„ç†ç¤ºä¾‹:");
    
    let client = LlmClient::new();
    
    // 1. æ— æ•ˆçš„ API å¯†é’¥
    let invalid_config = LlmConfig::openai("invalid-key");
    match client.add_config("invalid", invalid_config).await {
        Ok(_) => println!("ä¸åº”è¯¥æˆåŠŸ"),
        Err(e) => println!("é¢„æœŸçš„é”™è¯¯: {}", e),
    }
    
    // 2. ä½¿ç”¨ä¸å­˜åœ¨çš„é…ç½®
    match client.chat("Hello", Some("nonexistent")).await {
        Ok(_) => println!("ä¸åº”è¯¥æˆåŠŸ"),
        Err(e) => println!("é¢„æœŸçš„é”™è¯¯: {}", e),
    }
    
    // 3. æ²¡æœ‰é»˜è®¤é…ç½®
    match client.chat("Hello", None).await {
        Ok(_) => println!("ä¸åº”è¯¥æˆåŠŸ"),
        Err(e) => println!("é¢„æœŸçš„é”™è¯¯: {}", e),
    }
}
